{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "task4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yd50r_ugudR0",
        "2xDel1HMudSK",
        "HligwW7rudSN",
        "4gf97ttRudSR"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd50r_ugudR0",
        "colab_type": "text"
      },
      "source": [
        "### Install keras and tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF64RRuSudR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!conda install -c conda-forge keras --yes\n",
        "!conda install -c conda-forge tensorflow --yes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo-rQIyaudSB",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvtyxpDudSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNUKftv_udSG",
        "colab_type": "text"
      },
      "source": [
        "### Data import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvUJSuorudSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = 'food/'\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# load all images into a list\n",
        "file_list = sorted(os.listdir(folder_path))\n",
        "images = []\n",
        "for img in file_list:\n",
        "    if img == '.DS_Store':  # ignore stupid fookin mac file that wont go away\n",
        "        continue\n",
        "    img = os.path.join(folder_path, img)\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "\n",
        "# stack up images list to pass for prediction\n",
        "images = np.vstack(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDel1HMudSK",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcjazD1udSK",
        "colab_type": "code",
        "outputId": "5a3c4048-70fe-4237-860f-1dff5d843be7",
        "colab": {}
      },
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HligwW7rudSN",
        "colab_type": "text"
      },
      "source": [
        "### Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLH39nACudSO",
        "colab_type": "code",
        "outputId": "d80f3897-456b-4597-eeb4-e1001e34b0f1",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(images, batch_size=64, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3732s 373ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gf97ttRudSR",
        "colab_type": "text"
      },
      "source": [
        "### Save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwWCnuIJudSS",
        "colab_type": "code",
        "outputId": "954c9364-f0cb-4aa2-a82c-2e6c1e576e6f",
        "colab": {}
      },
      "source": [
        "# Save top 3 label probabilities as the 3 features describing image:\n",
        "predictions_decoded = np.array(decode_predictions(predictions, top=3))\n",
        "predictions_decoded = predictions_decoded[:, :, 1]\n",
        "\n",
        "df = pd.DataFrame(predictions_decoded, columns=['first', 'second', 'third'])\n",
        "print(df)\n",
        "\n",
        "df.to_csv('food_features', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMZFMlk6KsO",
        "colab_type": "text"
      },
      "source": [
        "# Load food features and one hot encode:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKFWtREudSf",
        "colab_type": "text"
      },
      "source": [
        "Now we need to load the newly generated features, train a neural net on the triplets with the new features and see what happens:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEejbvM7vAoQ",
        "colab_type": "text"
      },
      "source": [
        "Load food features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkU9aOL2udSf",
        "colab_type": "code",
        "outputId": "87f4bb45-1f46-4fce-908e-5194117a4d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_features = pd.read_csv(\"food_features\") \n",
        "print(df_features)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NplgRK1ArRgM",
        "colab_type": "text"
      },
      "source": [
        "Load triplets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U13XxZd_rURe",
        "colab_type": "code",
        "outputId": "c17dbad3-d853-479c-eee6-e10594891eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets = pd.read_csv('train_triplets.txt', sep=\" \", header=None)\n",
        "print(df_triplets)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59510   466  2952  2530\n",
            "59511  2646  3580  2359\n",
            "59512  3255  4844  4334\n",
            "59513  2136  4619   161\n",
            "59514  2509  2552  3406\n",
            "\n",
            "[59515 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCaMRS4_edk",
        "colab_type": "text"
      },
      "source": [
        "Somewhere around here we need to split into training and validation set. \n",
        "\n",
        "The issue is that the validation set triplets and training set triplets should not include any of the same images for the evaluation to be accurate. \n",
        "\n",
        "Maybe the easiest way to do this is to take some portion of the data as train set, and then iterate through the rest and if none of the three images are in the train set it goes in the validation set, otherwise if none of the three images are in the validation set it goes in the train set, otherwise it is discarded? Then tune the size of the initial train set to get ish the percent of the split we want? Very sub-optimal..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3LsIyDqBJDh",
        "colab_type": "code",
        "outputId": "eca148cf-f528-4265-c3f5-a9d0b5decb7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df_triplets_train = pd.DataFrame(columns = [0, 1, 2])\n",
        "df_triplets_val = pd.DataFrame(columns = [0, 1, 2])\n",
        "\n",
        "N = 325\n",
        "for idx, row in df_triplets.iterrows():\n",
        "  if idx < N:  # first N rows go in train\n",
        "    df_triplets_train = df_triplets_train.append(row)\n",
        "  elif all(x not in df_triplets_train.values for x in [row[0], row[1], row[2]]):  # else if images not in train add to val\n",
        "    df_triplets_val = df_triplets_val.append(row)\n",
        "  elif all(x not in df_triplets_val.values for x in [row[0], row[1], row[2]]):  # else if images not in val add to train\n",
        "    df_triplets_train = df_triplets_train.append(row)\n",
        "  # else we discard triplet\n",
        "  \n",
        "df_triplets_train = df_triplets_train.reset_index(drop=True)\n",
        "df_triplets_val = df_triplets_val.reset_index(drop=True)\n",
        "\n",
        "print(df_triplets_train)\n",
        "print(df_triplets_val)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "15887   450   219  4712\n",
            "15888   236  1229  4090\n",
            "15889   880  1818   621\n",
            "15890   466  2952  2530\n",
            "15891  2646  3580  2359\n",
            "\n",
            "[15892 rows x 3 columns]\n",
            "         0     1     2\n",
            "0      647  4571  3011\n",
            "1      683  2848  2039\n",
            "2     4404  2384  2478\n",
            "3     1019  4241  4114\n",
            "4     4108  1020  1523\n",
            "...    ...   ...   ...\n",
            "5000  4020  2390  1285\n",
            "5001  4990  4028  2647\n",
            "5002  1716  4431  3398\n",
            "5003  1550  1222  1140\n",
            "5004  1940    38  2869\n",
            "\n",
            "[5005 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCL7du2lqbVQ",
        "colab_type": "text"
      },
      "source": [
        "Problem: all the training data has label 1 right now.\n",
        "\n",
        "Attempt at solution: swap B and C for every other row, such that the labels are [1 0 1 0 1 ...]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeTs-B8rY0t",
        "colab_type": "code",
        "outputId": "49dfe92f-1c6f-44d1-d25c-6fec6d64b4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "for i, row in df_triplets_train.iterrows():\n",
        "  if i % 2 == 1:\n",
        "    temp = row[1]\n",
        "    df_triplets_train.at[i,1] = row[2]\n",
        "    df_triplets_train.at[i,2] = temp\n",
        "print(df_triplets_train)\n",
        "\n",
        "for i, row in df_triplets_val.iterrows():\n",
        "  if i % 2 == 1:\n",
        "    temp = row[1]\n",
        "    df_triplets_val.at[i,1] = row[2]\n",
        "    df_triplets_val.at[i,2] = temp\n",
        "print(df_triplets_val)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  4987  2499\n",
            "2      4663  1056  3029\n",
            "3      4532  1297  1186\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "15887   450  4712   219\n",
            "15888   236  1229  4090\n",
            "15889   880   621  1818\n",
            "15890   466  2952  2530\n",
            "15891  2646  2359  3580\n",
            "\n",
            "[15892 rows x 3 columns]\n",
            "         0     1     2\n",
            "0      647  4571  3011\n",
            "1      683  2039  2848\n",
            "2     4404  2384  2478\n",
            "3     1019  4114  4241\n",
            "4     4108  1020  1523\n",
            "...    ...   ...   ...\n",
            "5000  4020  2390  1285\n",
            "5001  4990  2647  4028\n",
            "5002  1716  4431  3398\n",
            "5003  1550  1140  1222\n",
            "5004  1940    38  2869\n",
            "\n",
            "[5005 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdY5M0Kp20tq",
        "colab_type": "code",
        "outputId": "672800dc-334d-40ab-8638-3fc783bd249b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets = pd.concat([df_triplets_train, df_triplets_val])  # Put the two dataframes back on top of each other\n",
        "\n",
        "df_triplets = df_triplets.reset_index(drop=True)  # Reset index column\n",
        "\n",
        "print(df_triplets)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  4987  2499\n",
            "2      4663  1056  3029\n",
            "3      4532  1297  1186\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "20892  4020  2390  1285\n",
            "20893  4990  2647  4028\n",
            "20894  1716  4431  3398\n",
            "20895  1550  1140  1222\n",
            "20896  1940    38  2869\n",
            "\n",
            "[20897 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtLAV_yh_HZm",
        "colab_type": "text"
      },
      "source": [
        "Generate dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3bdoH1s_GeO",
        "colab_type": "code",
        "outputId": "f281a09a-b059-4a1d-e796-50f71bed268f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "def generate_dataset(df_triplets, df_features):\n",
        "  #a = np.empty(shape=(df_triplets.shape[0], 9), dtype='object')\n",
        "  a = np.empty(shape=(df_triplets.shape[0], 3), dtype='object')\n",
        "\n",
        "  for i in range(3):\n",
        "    for idx, x in df_triplets[i].iteritems():\n",
        "      a[idx, i] = df_features.iloc[x, 0]\n",
        "      #a[idx, 3*i] = df_features.iloc[x, 0]\n",
        "      #a[idx, 3*i+1] = df_features.iloc[x, 1]\n",
        "      #a[idx, 3*i+2] = df_features.iloc[x, 2]\n",
        "\n",
        "  #df_triplets['A_1'], df_triplets['A_2'], df_triplets['A_3'] = [a[:, 0], a[:, 1], a[:, 2]]\n",
        "  #df_triplets['B_1'], df_triplets['B_2'], df_triplets['B_3'] = [a[:, 3], a[:, 4], a[:, 5]]\n",
        "  #df_triplets['C_1'], df_triplets['C_2'], df_triplets['C_3'] = [a[:, 6], a[:, 7], a[:, 8]]\n",
        "  df_triplets['A'] = a[:, 0]\n",
        "  df_triplets['B'] = a[:, 1]\n",
        "  df_triplets['C'] = a[:, 2]\n",
        "\n",
        "  return df_triplets\n",
        "\n",
        "df_triplets = generate_dataset(df_triplets, df_features)\n",
        "print(df_triplets)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2              A                 B                 C\n",
            "0      2461  3450  2678      ice_lolly   chocolate_sauce              tray\n",
            "1      2299  4987  2499  mashed_potato        frying_pan            switch\n",
            "2      4663  1056  3029         orange         barometer       cauliflower\n",
            "3      4532  1297  1186        pretzel  hen-of-the-woods           toaster\n",
            "4      3454  3809  2204          acorn               ant             plate\n",
            "...     ...   ...   ...            ...               ...               ...\n",
            "20892  4020  2390  1285          dough         meat_loaf       French_loaf\n",
            "20893  4990  2647  4028     neck_brace         meat_loaf  hen-of-the-woods\n",
            "20894  1716  4431  3398      meat_loaf       French_loaf            bolete\n",
            "20895  1550  1140  1222           corn          bolo_tie         artichoke\n",
            "20896  1940    38  2869            ear            potpie         guacamole\n",
            "\n",
            "[20897 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWrCI-qvGej",
        "colab_type": "text"
      },
      "source": [
        "*One*-hot encode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC53lwY-35B_",
        "colab_type": "code",
        "outputId": "756591fa-32bc-4cc9-a045-d68439cc61bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "df_triplets = df_triplets.drop(columns=[0, 1, 2])  # remove original image columns\n",
        "print(df_triplets)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A    coral_fungus\n",
            "B           pizza\n",
            "C          shovel\n",
            "Name: 15891, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPa7A-PzvAT7",
        "colab_type": "code",
        "outputId": "396f76f6-5eb5-4a65-9667-4f7e9c4aa694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets_oh = pd.get_dummies(data=df_triplets)\n",
        "print(df_triplets_oh)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_African_chameleon  A_African_crocodile  ...  C_zebra  C_zucchini\n",
            "0                        0                    0  ...        0           0\n",
            "1                        0                    0  ...        0           0\n",
            "2                        0                    0  ...        0           0\n",
            "3                        0                    0  ...        0           0\n",
            "4                        0                    0  ...        0           0\n",
            "...                    ...                  ...  ...      ...         ...\n",
            "20892                    0                    0  ...        0           0\n",
            "20893                    0                    0  ...        0           0\n",
            "20894                    0                    0  ...        0           0\n",
            "20895                    0                    0  ...        0           0\n",
            "20896                    0                    0  ...        0           0\n",
            "\n",
            "[20897 rows x 909 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQmWaI64Oo9",
        "colab_type": "code",
        "outputId": "f63759b8-e2ba-4335-9487-d32267a932de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df_triplets_train_oh = df_triplets_oh.iloc[:df_triplets_train.shape[0], :]\n",
        "df_triplets_val_oh = df_triplets_oh.iloc[df_triplets_train.shape[0]:, :]\n",
        "\n",
        "print(df_triplets_train_oh)\n",
        "print(df_triplets_val_oh)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_African_chameleon  A_African_crocodile  ...  C_zebra  C_zucchini\n",
            "0                        0                    0  ...        0           0\n",
            "1                        0                    0  ...        0           0\n",
            "2                        0                    0  ...        0           0\n",
            "3                        0                    0  ...        0           0\n",
            "4                        0                    0  ...        0           0\n",
            "...                    ...                  ...  ...      ...         ...\n",
            "15887                    0                    0  ...        0           0\n",
            "15888                    0                    0  ...        0           0\n",
            "15889                    0                    0  ...        0           0\n",
            "15890                    0                    0  ...        0           0\n",
            "15891                    0                    0  ...        0           0\n",
            "\n",
            "[15892 rows x 909 columns]\n",
            "       A_African_chameleon  A_African_crocodile  ...  C_zebra  C_zucchini\n",
            "15892                    0                    0  ...        0           0\n",
            "15893                    0                    0  ...        0           0\n",
            "15894                    0                    0  ...        0           0\n",
            "15895                    0                    0  ...        0           0\n",
            "15896                    0                    0  ...        0           0\n",
            "...                    ...                  ...  ...      ...         ...\n",
            "20892                    0                    0  ...        0           0\n",
            "20893                    0                    0  ...        0           0\n",
            "20894                    0                    0  ...        0           0\n",
            "20895                    0                    0  ...        0           0\n",
            "20896                    0                    0  ...        0           0\n",
            "\n",
            "[5005 rows x 909 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jG7D8YRM0Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save completed train and validation data sets:\n",
        "df_triplets_train_oh.to_csv('train', index=False)\n",
        "df_triplets_val_oh.to_csv('val', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A80ekfk5iaA",
        "colab_type": "text"
      },
      "source": [
        "# Train net:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGpVLchMi9Hb",
        "colab_type": "text"
      },
      "source": [
        "Load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-ffrYgi71Z",
        "colab_type": "code",
        "outputId": "128d779e-b3e3-449c-a500-4de8f6972277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "x_train = pd.read_csv('train')\n",
        "print(x_train)\n",
        "\n",
        "x_val = pd.read_csv('val')\n",
        "print(x_val)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_African_chameleon  A_African_crocodile  ...  C_zebra  C_zucchini\n",
            "0                        0                    0  ...        0           0\n",
            "1                        0                    0  ...        0           0\n",
            "2                        0                    0  ...        0           0\n",
            "3                        0                    0  ...        0           0\n",
            "4                        0                    0  ...        0           0\n",
            "...                    ...                  ...  ...      ...         ...\n",
            "15887                    0                    0  ...        0           0\n",
            "15888                    0                    0  ...        0           0\n",
            "15889                    0                    0  ...        0           0\n",
            "15890                    0                    0  ...        0           0\n",
            "15891                    0                    0  ...        0           0\n",
            "\n",
            "[15892 rows x 909 columns]\n",
            "      A_African_chameleon  A_African_crocodile  ...  C_zebra  C_zucchini\n",
            "0                       0                    0  ...        0           0\n",
            "1                       0                    0  ...        0           0\n",
            "2                       0                    0  ...        0           0\n",
            "3                       0                    0  ...        0           0\n",
            "4                       0                    0  ...        0           0\n",
            "...                   ...                  ...  ...      ...         ...\n",
            "5000                    0                    0  ...        0           0\n",
            "5001                    0                    0  ...        0           0\n",
            "5002                    0                    0  ...        0           0\n",
            "5003                    0                    0  ...        0           0\n",
            "5004                    0                    0  ...        0           0\n",
            "\n",
            "[5005 rows x 909 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEtL26Krtfzi",
        "colab_type": "text"
      },
      "source": [
        "Generate labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgqtlHl8thBf",
        "colab_type": "code",
        "outputId": "571067e6-39d7-40ae-9464-eb4583d80663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "y_train = np.empty((x_train.shape[0], 1))\n",
        "y_train[::2] = 1\n",
        "y_train[1::2] = 0\n",
        "print(y_train)\n",
        "\n",
        "y_val = np.empty((x_val.shape[0], 1))\n",
        "y_val[::2] = 1\n",
        "y_val[1::2] = 0\n",
        "print(y_val)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " ...\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCnNXx9Ei_i7",
        "colab_type": "text"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2-jXnAR5vTT",
        "colab_type": "code",
        "outputId": "fad847df-437c-490d-f1dd-98bab0d8569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(400, input_dim=x_train.shape[1], activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(400, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train.values, y_train, epochs=30, batch_size=32, shuffle=True, validation_data=(x_val.values, y_val))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.6881 - accuracy: 0.5348 - val_loss: 0.6918 - val_accuracy: 0.5353\n",
            "Epoch 2/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.6364 - accuracy: 0.6330 - val_loss: 0.7064 - val_accuracy: 0.5528\n",
            "Epoch 3/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.5260 - accuracy: 0.7302 - val_loss: 0.8090 - val_accuracy: 0.5495\n",
            "Epoch 4/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.3954 - accuracy: 0.8111 - val_loss: 0.9721 - val_accuracy: 0.5219\n",
            "Epoch 5/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.3053 - accuracy: 0.8592 - val_loss: 1.1422 - val_accuracy: 0.5381\n",
            "Epoch 6/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.2509 - accuracy: 0.8854 - val_loss: 1.2739 - val_accuracy: 0.5389\n",
            "Epoch 7/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.2179 - accuracy: 0.9006 - val_loss: 1.4332 - val_accuracy: 0.5502\n",
            "Epoch 8/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.2005 - accuracy: 0.9067 - val_loss: 1.4944 - val_accuracy: 0.5355\n",
            "Epoch 9/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1834 - accuracy: 0.9159 - val_loss: 1.5976 - val_accuracy: 0.5373\n",
            "Epoch 10/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1684 - accuracy: 0.9232 - val_loss: 1.7818 - val_accuracy: 0.5289\n",
            "Epoch 11/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1634 - accuracy: 0.9237 - val_loss: 1.8149 - val_accuracy: 0.5273\n",
            "Epoch 12/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1488 - accuracy: 0.9288 - val_loss: 1.9820 - val_accuracy: 0.5307\n",
            "Epoch 13/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1444 - accuracy: 0.9333 - val_loss: 2.0500 - val_accuracy: 0.5319\n",
            "Epoch 14/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1370 - accuracy: 0.9344 - val_loss: 2.1479 - val_accuracy: 0.5281\n",
            "Epoch 15/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1351 - accuracy: 0.9366 - val_loss: 2.1862 - val_accuracy: 0.5301\n",
            "Epoch 16/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1309 - accuracy: 0.9375 - val_loss: 2.2838 - val_accuracy: 0.5357\n",
            "Epoch 17/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1241 - accuracy: 0.9408 - val_loss: 2.3891 - val_accuracy: 0.5281\n",
            "Epoch 18/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1207 - accuracy: 0.9402 - val_loss: 2.2756 - val_accuracy: 0.5351\n",
            "Epoch 19/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1204 - accuracy: 0.9439 - val_loss: 2.3416 - val_accuracy: 0.5345\n",
            "Epoch 20/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1152 - accuracy: 0.9444 - val_loss: 2.5937 - val_accuracy: 0.5335\n",
            "Epoch 21/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1094 - accuracy: 0.9454 - val_loss: 2.5572 - val_accuracy: 0.5369\n",
            "Epoch 22/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1086 - accuracy: 0.9473 - val_loss: 2.6086 - val_accuracy: 0.5409\n",
            "Epoch 23/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1060 - accuracy: 0.9495 - val_loss: 2.6766 - val_accuracy: 0.5361\n",
            "Epoch 24/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1024 - accuracy: 0.9478 - val_loss: 2.7997 - val_accuracy: 0.5221\n",
            "Epoch 25/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1038 - accuracy: 0.9494 - val_loss: 2.7081 - val_accuracy: 0.5307\n",
            "Epoch 26/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.1002 - accuracy: 0.9506 - val_loss: 2.8273 - val_accuracy: 0.5315\n",
            "Epoch 27/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0995 - accuracy: 0.9509 - val_loss: 2.7832 - val_accuracy: 0.5335\n",
            "Epoch 28/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0968 - accuracy: 0.9527 - val_loss: 2.9619 - val_accuracy: 0.5277\n",
            "Epoch 29/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0951 - accuracy: 0.9509 - val_loss: 2.9654 - val_accuracy: 0.5249\n",
            "Epoch 30/30\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0964 - accuracy: 0.9522 - val_loss: 3.0350 - val_accuracy: 0.5357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ed2df8588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTe7y-afyXK8",
        "colab_type": "text"
      },
      "source": [
        "Hard: 0.688633839319\n",
        "\n",
        "Medium: \t0.627444380869\n",
        "\n",
        "Easy: \t0.578405304433"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7sRey_4xjgB",
        "colab_type": "text"
      },
      "source": [
        "Evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVgIaenlxkYQ",
        "colab_type": "code",
        "outputId": "4e40d0e9-1c78-41e2-ef7a-c3d6c6dc95e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "eval_results = model.evaluate(x_val, y_val, verbose=0) \n",
        "print(\"\\nLoss, accuracy on test data: \")\n",
        "print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
        "  eval_results[1]*100))\n",
        "\n",
        "predictions = model.predict_classes(x_val)\n",
        "print(predictions)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss, accuracy on test data: \n",
            "2.8106 50.97%\n",
            "WARNING:tensorflow:From <ipython-input-64-ca95b7d62007>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "[[1]\n",
            " [0]\n",
            " [1]\n",
            " ...\n",
            " [0]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLvjB7JAQ7QF",
        "colab_type": "text"
      },
      "source": [
        "# Predict on test set:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W5OPk9hRJW_",
        "colab_type": "text"
      },
      "source": [
        "### TODO: this must be done at the same time as the train data, such that test and train data have the exact same features, otherwise it is not compatable to use the model on the test data!!!\n",
        "\n",
        "Load test triplets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzkK_wuPRBjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "12c2e7ce-a63e-4ad1-a248-a1bbe22b73e9"
      },
      "source": [
        "df_triplets_test = pd.read_csv('test_triplets.txt', sep=\" \", header=None)\n",
        "print(df_triplets_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      9896  9640  9177\n",
            "1      6592  9283  7104\n",
            "2      8655  6174  6400\n",
            "3      9223  8187  8678\n",
            "4      7317  5392  9470\n",
            "...     ...   ...   ...\n",
            "59539  6113  8042  6277\n",
            "59540  8851  6075  8549\n",
            "59541  6299  7843  7940\n",
            "59542  7652  5620  5416\n",
            "59543  8475  6082  9044\n",
            "\n",
            "[59544 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aW1a9cPRb27",
        "colab_type": "text"
      },
      "source": [
        "Generate data set with imagenet features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHbjaHXvRdtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "27ccdbff-c7df-4bc9-c076-9dd73ec4a950"
      },
      "source": [
        "df_triplets_test = generate_dataset(df_triplets_test, df_features)\n",
        "df_triplets_test = df_triplets_test.drop(columns=[0, 1, 2])  # remove original image columns\n",
        "print(df_triplets_test)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               A_1         A_2  ...              C_2               C_3\n",
            "0      French_loaf      bakery  ...         bolo_tie          envelope\n",
            "1          burrito       plate  ...     wooden_spoon  butternut_squash\n",
            "2             chow     pretzel  ...            dough     custard_apple\n",
            "3            acorn         ear  ...           mortar       toilet_seat\n",
            "4           potpie       pizza  ...   Dungeness_crab         rock_crab\n",
            "...            ...         ...  ...              ...               ...\n",
            "59539  mixing_bowl   ice_cream  ...        meat_loaf     mashed_potato\n",
            "59540    ice_cream      banana  ...       Petri_dish          bolo_tie\n",
            "59541       chiton       conch  ...        soup_bowl               bib\n",
            "59542        plate   guacamole  ...           hotdog   chocolate_sauce\n",
            "59543       switch  saltshaker  ...  chocolate_sauce            candle\n",
            "\n",
            "[59544 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HyaRQYmR0Vm",
        "colab_type": "text"
      },
      "source": [
        "One hot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjty0yQqR1o8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f112bdac-eebc-4c24-ee32-00fd1f69c753"
      },
      "source": [
        "df_triplets_test_oh = pd.get_dummies(data=df_triplets_test)\n",
        "print(df_triplets_test_oh)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_American_lobster  A_1_Band_Aid  ...  C_3_wreck  C_3_zucchini\n",
            "0                         0             0  ...          0             0\n",
            "1                         0             0  ...          0             0\n",
            "2                         0             0  ...          0             0\n",
            "3                         0             0  ...          0             0\n",
            "4                         0             0  ...          0             0\n",
            "...                     ...           ...  ...        ...           ...\n",
            "59539                     0             0  ...          0             0\n",
            "59540                     0             0  ...          0             0\n",
            "59541                     0             0  ...          0             0\n",
            "59542                     0             0  ...          0             0\n",
            "59543                     0             0  ...          0             0\n",
            "\n",
            "[59544 rows x 3067 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3ugZFlzSAvC",
        "colab_type": "text"
      },
      "source": [
        "Save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2U92TtSSBNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_triplets_test_oh.to_csv('test', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL-D9dVFSE3e",
        "colab_type": "text"
      },
      "source": [
        "Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUEOMNcSF0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "7f798b7a-3a8c-43fc-d328-7f39755827d1"
      },
      "source": [
        "predictions = model.predict_classes(df_triplets_test_oh.values)\n",
        "print(predictions)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-51eae185e60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_triplets_test_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_15 is incompatible with the layer: expected axis -1 of input shape to have value 2950 but received input with shape [None, 3067]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dIZ0N8JSGC2",
        "colab_type": "text"
      },
      "source": [
        "Save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lbYFcURSGrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}