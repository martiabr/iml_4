{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "task4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yd50r_ugudR0",
        "2xDel1HMudSK",
        "HligwW7rudSN",
        "4gf97ttRudSR"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd50r_ugudR0",
        "colab_type": "text"
      },
      "source": [
        "### Install keras and tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF64RRuSudR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!conda install -c conda-forge keras --yes\n",
        "!conda install -c conda-forge tensorflow --yes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo-rQIyaudSB",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvtyxpDudSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNUKftv_udSG",
        "colab_type": "text"
      },
      "source": [
        "### Data import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvUJSuorudSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = 'food/'\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# load all images into a list\n",
        "file_list = sorted(os.listdir(folder_path))\n",
        "images = []\n",
        "for img in file_list:\n",
        "    if img == '.DS_Store':  # ignore stupid fookin mac file that wont go away\n",
        "        continue\n",
        "    img = os.path.join(folder_path, img)\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "\n",
        "# stack up images list to pass for prediction\n",
        "images = np.vstack(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDel1HMudSK",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcjazD1udSK",
        "colab_type": "code",
        "outputId": "5a3c4048-70fe-4237-860f-1dff5d843be7",
        "colab": {}
      },
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HligwW7rudSN",
        "colab_type": "text"
      },
      "source": [
        "### Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLH39nACudSO",
        "colab_type": "code",
        "outputId": "d80f3897-456b-4597-eeb4-e1001e34b0f1",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(images, batch_size=64, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3732s 373ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gf97ttRudSR",
        "colab_type": "text"
      },
      "source": [
        "### Save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwWCnuIJudSS",
        "colab_type": "code",
        "outputId": "954c9364-f0cb-4aa2-a82c-2e6c1e576e6f",
        "colab": {}
      },
      "source": [
        "# Save top 3 label probabilities as the 3 features describing image:\n",
        "predictions_decoded = np.array(decode_predictions(predictions, top=3))\n",
        "predictions_decoded = predictions_decoded[:, :, 1]\n",
        "\n",
        "df = pd.DataFrame(predictions_decoded, columns=['first', 'second', 'third'])\n",
        "print(df)\n",
        "\n",
        "df.to_csv('food_features', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMZFMlk6KsO",
        "colab_type": "text"
      },
      "source": [
        "# Load food features and one hot encode:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKFWtREudSf",
        "colab_type": "text"
      },
      "source": [
        "Now we need to load the newly generated features, train a neural net on the triplets with the new features and see what happens:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEejbvM7vAoQ",
        "colab_type": "text"
      },
      "source": [
        "Load food features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkU9aOL2udSf",
        "colab_type": "code",
        "outputId": "6e453810-9739-4961-b04a-f3e095dc87a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_features = pd.read_csv(\"food_features\") \n",
        "print(df_features)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NplgRK1ArRgM",
        "colab_type": "text"
      },
      "source": [
        "Load triplets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U13XxZd_rURe",
        "colab_type": "code",
        "outputId": "f0c87523-c9ca-44c9-8a0e-4d1ac9314a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets = pd.read_csv('train_triplets.txt', sep=\" \", header=None)\n",
        "print(df_triplets)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59510   466  2952  2530\n",
            "59511  2646  3580  2359\n",
            "59512  3255  4844  4334\n",
            "59513  2136  4619   161\n",
            "59514  2509  2552  3406\n",
            "\n",
            "[59515 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCaMRS4_edk",
        "colab_type": "text"
      },
      "source": [
        "Somewhere around here we need to split into training and validation set. \n",
        "\n",
        "The issue is that the validation set triplets and training set triplets should not include any of the same images for the evaluation to be accurate. \n",
        "\n",
        "Maybe the easiest way to do this is to take some portion of the data as train set, and then iterate through the rest and if none of the three images are in the train set it goes in the validation set, otherwise if none of the three images are in the validation set it goes in the train set, otherwise it is discarded? Then tune the size of the initial train set to get ish the percent of the split we want? Very sub-optimal..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3LsIyDqBJDh",
        "colab_type": "code",
        "outputId": "91bacb23-5e8e-46c6-a9eb-803b32b54604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df_triplets_train = pd.DataFrame(columns = [0, 1, 2])\n",
        "df_triplets_val = pd.DataFrame(columns = [0, 1, 2])\n",
        "\n",
        "N = 325\n",
        "for idx, row in df_triplets.iterrows():\n",
        "  if idx < N:  # first N rows go in train\n",
        "    df_triplets_train = df_triplets_train.append(row)\n",
        "  elif all(x not in df_triplets_train.values for x in [row[0], row[1], row[2]]):  # else if images not in train add to val\n",
        "    df_triplets_val = df_triplets_val.append(row)\n",
        "  elif all(x not in df_triplets_val.values for x in [row[0], row[1], row[2]]):  # else if images not in val add to train\n",
        "    df_triplets_train = df_triplets_train.append(row)\n",
        "  # else we discard triplet\n",
        "  \n",
        "df_triplets_train = df_triplets_train.reset_index(drop=True)\n",
        "df_triplets_val = df_triplets_val.reset_index(drop=True)\n",
        "\n",
        "print(df_triplets_train)\n",
        "print(df_triplets_val)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "15887   450   219  4712\n",
            "15888   236  1229  4090\n",
            "15889   880  1818   621\n",
            "15890   466  2952  2530\n",
            "15891  2646  3580  2359\n",
            "\n",
            "[15892 rows x 3 columns]\n",
            "         0     1     2\n",
            "0      647  4571  3011\n",
            "1      683  2848  2039\n",
            "2     4404  2384  2478\n",
            "3     1019  4241  4114\n",
            "4     4108  1020  1523\n",
            "...    ...   ...   ...\n",
            "5000  4020  2390  1285\n",
            "5001  4990  4028  2647\n",
            "5002  1716  4431  3398\n",
            "5003  1550  1222  1140\n",
            "5004  1940    38  2869\n",
            "\n",
            "[5005 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCL7du2lqbVQ",
        "colab_type": "text"
      },
      "source": [
        "Problem: all the training data has label 1 right now.\n",
        "\n",
        "Attempt at solution: swap B and C for every other row, such that the labels are [1 0 1 0 1 ...]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeTs-B8rY0t",
        "colab_type": "code",
        "outputId": "fdd5a40d-5ba5-4327-e007-c40daae43665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "for i, row in df_triplets_train.iterrows():\n",
        "  if i % 2 == 1:\n",
        "    temp = row[1]\n",
        "    df_triplets_train.at[i,1] = row[2]\n",
        "    df_triplets_train.at[i,2] = temp\n",
        "print(df_triplets_train)\n",
        "\n",
        "for i, row in df_triplets_val.iterrows():\n",
        "  if i % 2 == 1:\n",
        "    temp = row[1]\n",
        "    df_triplets_val.at[i,1] = row[2]\n",
        "    df_triplets_val.at[i,2] = temp\n",
        "print(df_triplets_val)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  4987  2499\n",
            "2      4663  1056  3029\n",
            "3      4532  1297  1186\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "15887   450  4712   219\n",
            "15888   236  1229  4090\n",
            "15889   880   621  1818\n",
            "15890   466  2952  2530\n",
            "15891  2646  2359  3580\n",
            "\n",
            "[15892 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i, row in df_triplets_val.iterrows():\\n  if i % 2 == 1:\\n    temp = row[1]\\n    df_triplets_val.at[i,1] = row[2]\\n    df_triplets_val.at[i,2] = temp\\nprint(df_triplets_val)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdY5M0Kp20tq",
        "colab_type": "code",
        "outputId": "6fe065ac-b67a-4450-dacc-3021c5151125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets = pd.concat([df_triplets_train, df_triplets_val])  # Put the two dataframes back on top of each other\n",
        "\n",
        "df_triplets = df_triplets.reset_index(drop=True)  # Reset index column\n",
        "\n",
        "print(df_triplets)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  4987  2499\n",
            "2      4663  1056  3029\n",
            "3      4532  1297  1186\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "20892  4020  2390  1285\n",
            "20893  4990  4028  2647\n",
            "20894  1716  4431  3398\n",
            "20895  1550  1222  1140\n",
            "20896  1940    38  2869\n",
            "\n",
            "[20897 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtLAV_yh_HZm",
        "colab_type": "text"
      },
      "source": [
        "Generate dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3bdoH1s_GeO",
        "colab_type": "code",
        "outputId": "6bde915b-c221-45e7-f190-a8394bdff773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "def generate_dataset(df_triplets, df_features):\n",
        "  a = np.empty(shape=(df_triplets.shape[0], 9), dtype='object')\n",
        "\n",
        "  for i in range(3):\n",
        "    for idx, x in df_triplets[i].iteritems():\n",
        "      a[idx, 3*i] = df_features.iloc[x, 0]\n",
        "      a[idx, 3*i+1] = df_features.iloc[x, 1]\n",
        "      a[idx, 3*i+2] = df_features.iloc[x, 2]\n",
        "\n",
        "  df_triplets['A_1'], df_triplets['A_2'], df_triplets['A_3'] = [a[:, 0], a[:, 1], a[:, 2]]\n",
        "  df_triplets['B_1'], df_triplets['B_2'], df_triplets['B_3'] = [a[:, 3], a[:, 4], a[:, 5]]\n",
        "  df_triplets['C_1'], df_triplets['C_2'], df_triplets['C_3'] = [a[:, 6], a[:, 7], a[:, 8]]\n",
        "\n",
        "  return df_triplets\n",
        "\n",
        "df_triplets = generate_dataset(df_triplets, df_features)\n",
        "print(df_triplets)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2  ...          C_1               C_2           C_3\n",
            "0      2461  3450  2678  ...         tray        strawberry      cucumber\n",
            "1      2299  4987  2499  ...       switch     jigsaw_puzzle    coral_reef\n",
            "2      4663  1056  3029  ...  cauliflower        rotisserie         plate\n",
            "3      4532  1297  1186  ...      toaster         meat_loaf    frying_pan\n",
            "4      3454  3809  2204  ...        plate  butternut_squash  acorn_squash\n",
            "...     ...   ...   ...  ...          ...               ...           ...\n",
            "20892  4020  2390  1285  ...  French_loaf            bakery         dough\n",
            "20893  4990  4028  2647  ...    meat_loaf     mashed_potato   mixing_bowl\n",
            "20894  1716  4431  3398  ...       bolete             plate        potpie\n",
            "20895  1550  1222  1140  ...     bolo_tie       waffle_iron     meat_loaf\n",
            "20896  1940    38  2869  ...    guacamole           burrito         plate\n",
            "\n",
            "[20897 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWrCI-qvGej",
        "colab_type": "text"
      },
      "source": [
        "*One*-hot encode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC53lwY-35B_",
        "colab_type": "code",
        "outputId": "b02b2e24-7469-49fc-994a-e563ecd81d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets = df_triplets.drop(columns=[0, 1, 2])  # remove original image columns\n",
        "print(df_triplets)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 A_1               A_2  ...               C_2           C_3\n",
            "0          ice_lolly        strawberry  ...        strawberry      cucumber\n",
            "1      mashed_potato         ice_cream  ...     jigsaw_puzzle    coral_reef\n",
            "2             orange               hip  ...        rotisserie         plate\n",
            "3            pretzel             bagel  ...         meat_loaf    frying_pan\n",
            "4              acorn               hip  ...  butternut_squash  acorn_squash\n",
            "...              ...               ...  ...               ...           ...\n",
            "20892          dough            bakery  ...            bakery         dough\n",
            "20893     neck_brace            potpie  ...     mashed_potato   mixing_bowl\n",
            "20894      meat_loaf       French_loaf  ...             plate        potpie\n",
            "20895           corn               ear  ...       waffle_iron     meat_loaf\n",
            "20896            ear  spaghetti_squash  ...           burrito         plate\n",
            "\n",
            "[20897 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPa7A-PzvAT7",
        "colab_type": "code",
        "outputId": "0e9753ce-8534-44e1-a9c0-ef6e912b0f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df_triplets_oh = pd.get_dummies(data=df_triplets)\n",
        "print(df_triplets_oh)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "20892                      0                      0  ...          0             0\n",
            "20893                      0                      0  ...          0             0\n",
            "20894                      0                      0  ...          0             0\n",
            "20895                      0                      0  ...          0             0\n",
            "20896                      0                      0  ...          0             0\n",
            "\n",
            "[20897 rows x 2950 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQmWaI64Oo9",
        "colab_type": "code",
        "outputId": "e809d715-26bf-4d51-a55a-12a6156ef4ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "df_triplets_train_oh = df_triplets_oh.iloc[:df_triplets_train.shape[0], :]\n",
        "df_triplets_val_oh = df_triplets_oh.iloc[df_triplets_train.shape[0]:, :]\n",
        "\n",
        "print(df_triplets_train_oh)\n",
        "print(df_triplets_val_oh)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "15887                      0                      0  ...          0             0\n",
            "15888                      0                      0  ...          0             0\n",
            "15889                      0                      0  ...          0             0\n",
            "15890                      0                      0  ...          0             0\n",
            "15891                      0                      0  ...          0             0\n",
            "\n",
            "[15892 rows x 2950 columns]\n",
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "15892                      0                      0  ...          0             0\n",
            "15893                      0                      0  ...          0             0\n",
            "15894                      0                      0  ...          0             0\n",
            "15895                      0                      0  ...          0             0\n",
            "15896                      0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "20892                      0                      0  ...          0             0\n",
            "20893                      0                      0  ...          0             0\n",
            "20894                      0                      0  ...          0             0\n",
            "20895                      0                      0  ...          0             0\n",
            "20896                      0                      0  ...          0             0\n",
            "\n",
            "[5005 rows x 2950 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jG7D8YRM0Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save completed train and validation data sets:\n",
        "df_triplets_train_oh.to_csv('train', index=False)\n",
        "df_triplets_val_oh.to_csv('val', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A80ekfk5iaA",
        "colab_type": "text"
      },
      "source": [
        "# Train net:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGpVLchMi9Hb",
        "colab_type": "text"
      },
      "source": [
        "Load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-ffrYgi71Z",
        "colab_type": "code",
        "outputId": "460c5b87-9251-49f5-a3da-0e350715d84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "x_train = pd.read_csv('train')\n",
        "print(x_train)\n",
        "\n",
        "x_val = pd.read_csv('val')\n",
        "print(x_val)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "15887                      0                      0  ...          0             0\n",
            "15888                      0                      0  ...          0             0\n",
            "15889                      0                      0  ...          0             0\n",
            "15890                      0                      0  ...          0             0\n",
            "15891                      0                      0  ...          0             0\n",
            "\n",
            "[15892 rows x 2950 columns]\n",
            "      A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                         0                      0  ...          0             0\n",
            "1                         0                      0  ...          0             0\n",
            "2                         0                      0  ...          0             0\n",
            "3                         0                      0  ...          0             0\n",
            "4                         0                      0  ...          0             0\n",
            "...                     ...                    ...  ...        ...           ...\n",
            "5000                      0                      0  ...          0             0\n",
            "5001                      0                      0  ...          0             0\n",
            "5002                      0                      0  ...          0             0\n",
            "5003                      0                      0  ...          0             0\n",
            "5004                      0                      0  ...          0             0\n",
            "\n",
            "[5005 rows x 2950 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEtL26Krtfzi",
        "colab_type": "text"
      },
      "source": [
        "Generate labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgqtlHl8thBf",
        "colab_type": "code",
        "outputId": "ab1840d0-ec33-4710-c59d-c3b0cd44375c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "y_train = np.empty((x_train.shape[0], 1))\n",
        "y_train[::2] = 1\n",
        "y_train[1::2] = 0\n",
        "print(y_train)\n",
        "\n",
        "y_val = np.empty((x_val.shape[0], 1))\n",
        "y_val[::2] = 1\n",
        "y_val[1::2] = 0\n",
        "print(y_val)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " ...\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]]\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCnNXx9Ei_i7",
        "colab_type": "text"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2-jXnAR5vTT",
        "colab_type": "code",
        "outputId": "d7f7bb42-70f4-4659-9556-d6f0dc5f2f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(1000, input_dim=x_train.shape[1], activation='relu'))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1000, activation='relu'))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train.values, y_train, epochs=10, batch_size=32, shuffle=True, validation_data=(x_val.values,y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "497/497 [==============================] - 16s 31ms/step - loss: 0.6744 - accuracy: 0.5720 - val_loss: 0.6071 - val_accuracy: 0.7143\n",
            "Epoch 2/10\n",
            "497/497 [==============================] - 16s 31ms/step - loss: 0.4644 - accuracy: 0.7839 - val_loss: 0.8425 - val_accuracy: 0.5630\n",
            "Epoch 3/10\n",
            "497/497 [==============================] - 16s 32ms/step - loss: 0.0880 - accuracy: 0.9687 - val_loss: 1.3674 - val_accuracy: 0.5876\n",
            "Epoch 4/10\n",
            "385/497 [======================>.......] - ETA: 3s - loss: 0.0139 - accuracy: 0.9959"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTe7y-afyXK8",
        "colab_type": "text"
      },
      "source": [
        "Hard: 0.688633839319\n",
        "\n",
        "Medium: \t0.627444380869\n",
        "\n",
        "Easy: \t0.578405304433"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Rstpr7zaOk",
        "colab_type": "text"
      },
      "source": [
        "Generate test data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvCbOB7zdhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate test data here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7sRey_4xjgB",
        "colab_type": "text"
      },
      "source": [
        "Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVgIaenlxkYQ",
        "colab_type": "code",
        "outputId": "246648ff-0809-4411-fa21-d4649bfb57da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "eval_results = model.evaluate(x_val, y_val, verbose=0) \n",
        "print(\"\\nLoss, accuracy on test data: \")\n",
        "print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
        "  eval_results[1]*100))\n",
        "\n",
        "predictions = model.predict_classes(x_val)\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss, accuracy on test data: \n",
            "5.9344 38.46%\n",
            "[[1]\n",
            " [0]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}