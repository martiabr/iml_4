{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "task4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yd50r_ugudR0",
        "KNUKftv_udSG",
        "2xDel1HMudSK",
        "HligwW7rudSN",
        "4gf97ttRudSR"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd50r_ugudR0",
        "colab_type": "text"
      },
      "source": [
        "### Install keras and tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF64RRuSudR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!conda install -c conda-forge keras --yes\n",
        "!conda install -c conda-forge tensorflow --yes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo-rQIyaudSB",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvtyxpDudSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNUKftv_udSG",
        "colab_type": "text"
      },
      "source": [
        "### Data import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvUJSuorudSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = 'food/'\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# load all images into a list\n",
        "file_list = sorted(os.listdir(folder_path))\n",
        "images = []\n",
        "for img in file_list:\n",
        "    if img == '.DS_Store':  # ignore stupid fookin mac file that wont go away\n",
        "        continue\n",
        "    img = os.path.join(folder_path, img)\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "\n",
        "# stack up images list to pass for prediction\n",
        "images = np.vstack(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDel1HMudSK",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcjazD1udSK",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a3c4048-70fe-4237-860f-1dff5d843be7"
      },
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HligwW7rudSN",
        "colab_type": "text"
      },
      "source": [
        "### Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLH39nACudSO",
        "colab_type": "code",
        "colab": {},
        "outputId": "d80f3897-456b-4597-eeb4-e1001e34b0f1"
      },
      "source": [
        "predictions = model.predict(images, batch_size=64, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3732s 373ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gf97ttRudSR",
        "colab_type": "text"
      },
      "source": [
        "### Save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwWCnuIJudSS",
        "colab_type": "code",
        "colab": {},
        "outputId": "954c9364-f0cb-4aa2-a82c-2e6c1e576e6f"
      },
      "source": [
        "# Save top 3 label probabilities as the 3 features describing image:\n",
        "predictions_decoded = np.array(decode_predictions(predictions, top=3))\n",
        "predictions_decoded = predictions_decoded[:, :, 1]\n",
        "\n",
        "df = pd.DataFrame(predictions_decoded, columns=['first', 'second', 'third'])\n",
        "print(df)\n",
        "\n",
        "df.to_csv('food_features', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HMxa-5VudSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-xu_ITudSa",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4c6fef9-ab95-4258-c098-c2f8f3ee942b"
      },
      "source": [
        "'''img_path = 'food/00000.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "pred = model.predict(x)\n",
        "pred = np.array(decode_predictions(pred, top=3))\n",
        "print(pred)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[['n04423845' 'thimble' '0.7259098']\n",
            "  ['n01768244' 'trilobite' '0.102758445']\n",
            "  ['n03871628' 'packet' '0.019814285']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi3OahdzudSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMZFMlk6KsO",
        "colab_type": "text"
      },
      "source": [
        "# Load food features and one hot encode:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKFWtREudSf",
        "colab_type": "text"
      },
      "source": [
        "Now we need to load the newly generated features, train a neural net on the triplets with the new features and see what happens:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEejbvM7vAoQ",
        "colab_type": "text"
      },
      "source": [
        "Load food features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkU9aOL2udSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b82ecc31-b707-4758-bbed-2e0eac20d0f1"
      },
      "source": [
        "df_features = pd.read_csv(\"food_features\") \n",
        "print(df_features)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NplgRK1ArRgM",
        "colab_type": "text"
      },
      "source": [
        "Load triplets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U13XxZd_rURe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9cc33cb4-344b-4b12-dad4-b06313c5d09d"
      },
      "source": [
        "df_triplets = pd.read_csv('train_triplets.txt', sep=\" \", header=None)\n",
        "print(df_triplets)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59510   466  2952  2530\n",
            "59511  2646  3580  2359\n",
            "59512  3255  4844  4334\n",
            "59513  2136  4619   161\n",
            "59514  2509  2552  3406\n",
            "\n",
            "[59515 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCaMRS4_edk",
        "colab_type": "text"
      },
      "source": [
        "Somewhere around here we need to split into training and validation set. \n",
        "\n",
        "The issue is that the validation set triplets and training set triplets should not include any of the same images for the evaluation to be accurate. \n",
        "\n",
        "Maybe the easiest way to do this is to take some portion of the data as train set, and then iterate through the rest and if none of the three images are in the train set it goes in the validation set, otherwise if none of the three images are in the validation set it goes in the train set, otherwise it is discarded? Then tune the size of the initial train set to get ish the percent of the split we want? Very sub-optimal..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3LsIyDqBJDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "669d27d5-1f70-4fd2-a618-5a9957e8f086"
      },
      "source": [
        "df_triplets_train = pd.DataFrame(columns = [0, 1, 2])\n",
        "df_triplets_val = pd.DataFrame(columns = [0, 1, 2])\n",
        "\n",
        "for idx, row in df_triplets.iterrows():\n",
        "  if idx < 400:  # first N rows go in train\n",
        "    df_triplets_train = df_triplets_train.append(row)\n",
        "  elif all(x not in df_triplets_train.values for x in [row[0], row[1], row[2]]):  # else if images not in train add to val\n",
        "    df_triplets_val = df_triplets_val.append(row)\n",
        "  elif all(x not in df_triplets_val.values for x in [row[0], row[1], row[2]]):  # else if images not in val add to train\n",
        "    df_triplets_train = df_triplets_train.append(row)\n",
        "  # else we discard triplet\n",
        "\n",
        "print(df_triplets_train)\n",
        "print(df_triplets_val)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59503   236  1229  4090\n",
            "59507  1724  4031  3482\n",
            "59509   880  1818   621\n",
            "59510   466  2952  2530\n",
            "59511  2646  3580  2359\n",
            "\n",
            "[28982 rows x 3 columns]\n",
            "          0     1     2\n",
            "501    1582  4879  1439\n",
            "505    2024  1829  1990\n",
            "506    2029  2946  4207\n",
            "509    3271  1538  4774\n",
            "514    4773  1995  1182\n",
            "...     ...   ...   ...\n",
            "59253  4830  1157  3892\n",
            "59282  3012  2395  2788\n",
            "59468  4990  4028  2647\n",
            "59481  1550  1222  1140\n",
            "59496  1940    38  2869\n",
            "\n",
            "[1533 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCL7du2lqbVQ",
        "colab_type": "text"
      },
      "source": [
        "Problem: all the training data has label 1 right now.\n",
        "\n",
        "Attempt at solution: swap B and C for every other row, such that the labels are [1 0 1 0 1 ...]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeTs-B8rY0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9f9a6068-c0fc-4758-9f43-201e1152276c"
      },
      "source": [
        " for i, row in df_triplets.iterrows():\n",
        "  if i % 2 == 1:\n",
        "    temp = row[1]\n",
        "    df_triplets.at[i,1] = row[2]\n",
        "    df_triplets.at[i,2] = temp\n",
        "print(df_triplets)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  4987  2499\n",
            "2      4663  1056  3029\n",
            "3      4532  1297  1186\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59510   466  2952  2530\n",
            "59511  2646  2359  3580\n",
            "59512  3255  4844  4334\n",
            "59513  2136   161  4619\n",
            "59514  2509  2552  3406\n",
            "\n",
            "[59515 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtLAV_yh_HZm",
        "colab_type": "text"
      },
      "source": [
        "Generate dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3bdoH1s_GeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3ff88d4e-faef-4db2-fa68-97cfc5183be6"
      },
      "source": [
        "a = np.empty(shape=(df_triplets.shape[0],9), dtype='object')\n",
        "\n",
        "for i in range(3):\n",
        "  for idx, x in df_triplets[i].iteritems():\n",
        "    a[idx, 3*i] = df_features.iloc[x, 0]\n",
        "    a[idx, 3*i+1] = df_features.iloc[x, 1]\n",
        "    a[idx, 3*i+2] = df_features.iloc[x, 2]\n",
        "\n",
        "df_triplets['A_1'], df_triplets['A_2'], df_triplets['A_3'] = [a[:, 0], a[:, 1], a[:, 2]]\n",
        "df_triplets['B_1'], df_triplets['B_2'], df_triplets['B_3'] = [a[:, 3], a[:, 4], a[:, 5]]\n",
        "df_triplets['C_1'], df_triplets['C_2'], df_triplets['C_3'] = [a[:, 6], a[:, 7], a[:, 8]]\n",
        "\n",
        "df_triplets = df_triplets.drop(columns=[0, 1, 2])\n",
        "\n",
        "print(df_triplets)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 A_1            A_2  ...               C_2           C_3\n",
            "0          ice_lolly     strawberry  ...        strawberry      cucumber\n",
            "1      mashed_potato      ice_cream  ...     jigsaw_puzzle    coral_reef\n",
            "2             orange            hip  ...        rotisserie         plate\n",
            "3            pretzel          bagel  ...         meat_loaf    frying_pan\n",
            "4              acorn            hip  ...  butternut_squash  acorn_squash\n",
            "...              ...            ...  ...               ...           ...\n",
            "59510          plate       broccoli  ...          broccoli         plate\n",
            "59511   coral_fungus          dough  ...           spatula     ice_cream\n",
            "59512      soup_bowl        hot_pot  ...  pencil_sharpener       toaster\n",
            "59513          plate  mashed_potato  ...             pizza   cauliflower\n",
            "59514  mashed_potato      meat_loaf  ...         carbonara     guacamole\n",
            "\n",
            "[59515 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWrCI-qvGej",
        "colab_type": "text"
      },
      "source": [
        "One-hot encode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPa7A-PzvAT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ccac684b-acd4-487d-efdc-f6f3d24e84c3"
      },
      "source": [
        "df_triplets_oh = pd.get_dummies(data=df_triplets)\n",
        "print(df_triplets_oh)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "59510                      0                      0  ...          0             0\n",
            "59511                      0                      0  ...          0             0\n",
            "59512                      0                      0  ...          0             0\n",
            "59513                      0                      0  ...          0             0\n",
            "59514                      0                      0  ...          0             0\n",
            "\n",
            "[59515 rows x 3093 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIsYaK_0hhCn",
        "colab_type": "text"
      },
      "source": [
        "Save again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7KSNOuThh7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_triplets_oh.to_csv('train_triplets_oh', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A80ekfk5iaA",
        "colab_type": "text"
      },
      "source": [
        "# Train net:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGpVLchMi9Hb",
        "colab_type": "text"
      },
      "source": [
        "Load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-ffrYgi71Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "373bc9c5-f4b5-49af-83b8-21f3c510e49d"
      },
      "source": [
        "x_train = pd.read_csv('train_triplets_oh')\n",
        "print(x_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "59510                      0                      0  ...          0             0\n",
            "59511                      0                      0  ...          0             0\n",
            "59512                      0                      0  ...          0             0\n",
            "59513                      0                      0  ...          0             0\n",
            "59514                      0                      0  ...          0             0\n",
            "\n",
            "[59515 rows x 3093 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEtL26Krtfzi",
        "colab_type": "text"
      },
      "source": [
        "Generate labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgqtlHl8thBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3dfbfa64-77e3-434e-c957-771e937bde96"
      },
      "source": [
        "y_train = np.empty((x_train.shape[0],1))\n",
        "y_train[::2] = 1\n",
        "y_train[1::2] = 0\n",
        "print(y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCnNXx9Ei_i7",
        "colab_type": "text"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2-jXnAR5vTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "da7c8686-fb6a-4c15-e5b1-95c8bac2ed84"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(800, input_dim=x_train.shape[1], activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(layers.Dense(800, activation='relu'))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train.values, y_train, epochs=5, batch_size=32, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.6474 - accuracy: 0.6086 - val_loss: 0.5970 - val_accuracy: 0.6651\n",
            "Epoch 2/5\n",
            "1488/1488 [==============================] - 37s 25ms/step - loss: 0.4481 - accuracy: 0.7876 - val_loss: 0.5363 - val_accuracy: 0.7459\n",
            "Epoch 3/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.6761 - val_accuracy: 0.7770\n",
            "Epoch 4/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.9484 - val_accuracy: 0.7846\n",
            "Epoch 5/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.1446 - val_accuracy: 0.7894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2932167668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTe7y-afyXK8",
        "colab_type": "text"
      },
      "source": [
        "Hard: 0.688633839319\n",
        "\n",
        "Medium: \t0.627444380869\n",
        "\n",
        "Easy: \t0.578405304433"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Rstpr7zaOk",
        "colab_type": "text"
      },
      "source": [
        "Generate test data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvCbOB7zdhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate test data here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7sRey_4xjgB",
        "colab_type": "text"
      },
      "source": [
        "Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVgIaenlxkYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}