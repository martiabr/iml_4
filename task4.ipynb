{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "task4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yd50r_ugudR0",
        "KNUKftv_udSG",
        "2xDel1HMudSK",
        "HligwW7rudSN",
        "4gf97ttRudSR"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd50r_ugudR0",
        "colab_type": "text"
      },
      "source": [
        "### Install keras and tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF64RRuSudR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!conda install -c conda-forge keras --yes\n",
        "!conda install -c conda-forge tensorflow --yes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo-rQIyaudSB",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvtyxpDudSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNUKftv_udSG",
        "colab_type": "text"
      },
      "source": [
        "### Data import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvUJSuorudSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = 'food/'\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# load all images into a list\n",
        "file_list = sorted(os.listdir(folder_path))\n",
        "images = []\n",
        "for img in file_list:\n",
        "    if img == '.DS_Store':  # ignore stupid fookin mac file that wont go away\n",
        "        continue\n",
        "    img = os.path.join(folder_path, img)\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "\n",
        "# stack up images list to pass for prediction\n",
        "images = np.vstack(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xDel1HMudSK",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcjazD1udSK",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a3c4048-70fe-4237-860f-1dff5d843be7"
      },
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/martinbrandt/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HligwW7rudSN",
        "colab_type": "text"
      },
      "source": [
        "### Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLH39nACudSO",
        "colab_type": "code",
        "colab": {},
        "outputId": "d80f3897-456b-4597-eeb4-e1001e34b0f1"
      },
      "source": [
        "predictions = model.predict(images, batch_size=64, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3732s 373ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gf97ttRudSR",
        "colab_type": "text"
      },
      "source": [
        "### Save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwWCnuIJudSS",
        "colab_type": "code",
        "colab": {},
        "outputId": "954c9364-f0cb-4aa2-a82c-2e6c1e576e6f"
      },
      "source": [
        "# Save top 3 label probabilities as the 3 features describing image:\n",
        "predictions_decoded = np.array(decode_predictions(predictions, top=3))\n",
        "predictions_decoded = predictions_decoded[:, :, 1]\n",
        "\n",
        "df = pd.DataFrame(predictions_decoded, columns=['first', 'second', 'third'])\n",
        "print(df)\n",
        "\n",
        "df.to_csv('food_features', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HMxa-5VudSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-xu_ITudSa",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4c6fef9-ab95-4258-c098-c2f8f3ee942b"
      },
      "source": [
        "'''img_path = 'food/00000.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "pred = model.predict(x)\n",
        "pred = np.array(decode_predictions(pred, top=3))\n",
        "print(pred)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[['n04423845' 'thimble' '0.7259098']\n",
            "  ['n01768244' 'trilobite' '0.102758445']\n",
            "  ['n03871628' 'packet' '0.019814285']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi3OahdzudSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMZFMlk6KsO",
        "colab_type": "text"
      },
      "source": [
        "# Load food features and one hot encode:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKFWtREudSf",
        "colab_type": "text"
      },
      "source": [
        "Now we need to load the newly generated features, train a neural net on the triplets with the new features and see what happens:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEejbvM7vAoQ",
        "colab_type": "text"
      },
      "source": [
        "Load food features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkU9aOL2udSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b82ecc31-b707-4758-bbed-2e0eac20d0f1"
      },
      "source": [
        "df_features = pd.read_csv(\"food_features\") \n",
        "print(df_features)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           first         second         third\n",
            "0        thimble      trilobite        packet\n",
            "1         potpie         bakery         dough\n",
            "2      ice_cream  mashed_potato         dough\n",
            "3      ice_cream          dough     meat_loaf\n",
            "4        burrito        pretzel     carbonara\n",
            "...          ...            ...           ...\n",
            "9995   ice_cream     neck_brace      lipstick\n",
            "9996  strawberry      ice_cream      baseball\n",
            "9997   meat_loaf          pizza  wooden_spoon\n",
            "9998   soup_bowl     frying_pan         loupe\n",
            "9999       dough           wool        mortar\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NplgRK1ArRgM",
        "colab_type": "text"
      },
      "source": [
        "Load triplets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U13XxZd_rURe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2773400a-a1fc-4a6f-e0ae-c92800e28ba4"
      },
      "source": [
        "df_triplets = pd.read_csv('train_triplets.txt', sep=\" \", header=None)\n",
        "print(df_triplets)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  2499  4987\n",
            "2      4663  1056  3029\n",
            "3      4532  1186  1297\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59510   466  2952  2530\n",
            "59511  2646  3580  2359\n",
            "59512  3255  4844  4334\n",
            "59513  2136  4619   161\n",
            "59514  2509  2552  3406\n",
            "\n",
            "[59515 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCaMRS4_edk",
        "colab_type": "text"
      },
      "source": [
        "Somewhere around here we need to split into training and validation set. \n",
        "\n",
        "The issue is that the validation set triplets and training set triplets should not include any of the same images for the evaluation to be accurate. \n",
        "\n",
        "Maybe the easiest way to do this is to take some portion of the data as train set, and then iterate through the rest and if none of the three images are in the train set it goes in the validation set, otherwise if none of the three images are in the validation set it goes in the train set, otherwise it is discarded? Then tune the size of the initial train set to get ish the percent of the split we want?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCL7du2lqbVQ",
        "colab_type": "text"
      },
      "source": [
        "Problem: all the training data has label 1 right now.\n",
        "\n",
        "Attempt at solution: swap B and C for every other row, such that the labels are [1 0 1 0 1 ...]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeTs-B8rY0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9f9a6068-c0fc-4758-9f43-201e1152276c"
      },
      "source": [
        " for i, row in df_triplets.iterrows():\n",
        "  if i % 2 == 1:\n",
        "    temp = row[1]\n",
        "    df_triplets.at[i,1] = row[2]\n",
        "    df_triplets.at[i,2] = temp\n",
        "print(df_triplets)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1     2\n",
            "0      2461  3450  2678\n",
            "1      2299  4987  2499\n",
            "2      4663  1056  3029\n",
            "3      4532  1297  1186\n",
            "4      3454  3809  2204\n",
            "...     ...   ...   ...\n",
            "59510   466  2952  2530\n",
            "59511  2646  2359  3580\n",
            "59512  3255  4844  4334\n",
            "59513  2136   161  4619\n",
            "59514  2509  2552  3406\n",
            "\n",
            "[59515 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtLAV_yh_HZm",
        "colab_type": "text"
      },
      "source": [
        "Generate dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3bdoH1s_GeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3ff88d4e-faef-4db2-fa68-97cfc5183be6"
      },
      "source": [
        "a = np.empty(shape=(df_triplets.shape[0],9), dtype='object')\n",
        "\n",
        "for i in range(3):\n",
        "  for idx, x in df_triplets[i].iteritems():\n",
        "    a[idx, 3*i] = df_features.iloc[x, 0]\n",
        "    a[idx, 3*i+1] = df_features.iloc[x, 1]\n",
        "    a[idx, 3*i+2] = df_features.iloc[x, 2]\n",
        "\n",
        "df_triplets['A_1'], df_triplets['A_2'], df_triplets['A_3'] = [a[:, 0], a[:, 1], a[:, 2]]\n",
        "df_triplets['B_1'], df_triplets['B_2'], df_triplets['B_3'] = [a[:, 3], a[:, 4], a[:, 5]]\n",
        "df_triplets['C_1'], df_triplets['C_2'], df_triplets['C_3'] = [a[:, 6], a[:, 7], a[:, 8]]\n",
        "\n",
        "df_triplets = df_triplets.drop(columns=[0, 1, 2])\n",
        "\n",
        "print(df_triplets)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 A_1            A_2  ...               C_2           C_3\n",
            "0          ice_lolly     strawberry  ...        strawberry      cucumber\n",
            "1      mashed_potato      ice_cream  ...     jigsaw_puzzle    coral_reef\n",
            "2             orange            hip  ...        rotisserie         plate\n",
            "3            pretzel          bagel  ...         meat_loaf    frying_pan\n",
            "4              acorn            hip  ...  butternut_squash  acorn_squash\n",
            "...              ...            ...  ...               ...           ...\n",
            "59510          plate       broccoli  ...          broccoli         plate\n",
            "59511   coral_fungus          dough  ...           spatula     ice_cream\n",
            "59512      soup_bowl        hot_pot  ...  pencil_sharpener       toaster\n",
            "59513          plate  mashed_potato  ...             pizza   cauliflower\n",
            "59514  mashed_potato      meat_loaf  ...         carbonara     guacamole\n",
            "\n",
            "[59515 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWrCI-qvGej",
        "colab_type": "text"
      },
      "source": [
        "One-hot encode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPa7A-PzvAT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ccac684b-acd4-487d-efdc-f6f3d24e84c3"
      },
      "source": [
        "df_triplets_oh = pd.get_dummies(data=df_triplets)\n",
        "print(df_triplets_oh)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "59510                      0                      0  ...          0             0\n",
            "59511                      0                      0  ...          0             0\n",
            "59512                      0                      0  ...          0             0\n",
            "59513                      0                      0  ...          0             0\n",
            "59514                      0                      0  ...          0             0\n",
            "\n",
            "[59515 rows x 3093 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIsYaK_0hhCn",
        "colab_type": "text"
      },
      "source": [
        "Save again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7KSNOuThh7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_triplets_oh.to_csv('train_triplets_oh', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A80ekfk5iaA",
        "colab_type": "text"
      },
      "source": [
        "# Train net:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGpVLchMi9Hb",
        "colab_type": "text"
      },
      "source": [
        "Load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-ffrYgi71Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "373bc9c5-f4b5-49af-83b8-21f3c510e49d"
      },
      "source": [
        "x_train = pd.read_csv('train_triplets_oh')\n",
        "print(x_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       A_1_African_chameleon  A_1_African_crocodile  ...  C_3_wreck  C_3_zucchini\n",
            "0                          0                      0  ...          0             0\n",
            "1                          0                      0  ...          0             0\n",
            "2                          0                      0  ...          0             0\n",
            "3                          0                      0  ...          0             0\n",
            "4                          0                      0  ...          0             0\n",
            "...                      ...                    ...  ...        ...           ...\n",
            "59510                      0                      0  ...          0             0\n",
            "59511                      0                      0  ...          0             0\n",
            "59512                      0                      0  ...          0             0\n",
            "59513                      0                      0  ...          0             0\n",
            "59514                      0                      0  ...          0             0\n",
            "\n",
            "[59515 rows x 3093 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEtL26Krtfzi",
        "colab_type": "text"
      },
      "source": [
        "Generate labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgqtlHl8thBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3dfbfa64-77e3-434e-c957-771e937bde96"
      },
      "source": [
        "y_train = np.empty((x_train.shape[0],1))\n",
        "y_train[::2] = 1\n",
        "y_train[1::2] = 0\n",
        "print(y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCnNXx9Ei_i7",
        "colab_type": "text"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2-jXnAR5vTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "da7c8686-fb6a-4c15-e5b1-95c8bac2ed84"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(800, input_dim=x_train.shape[1], activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(layers.Dense(800, activation='relu'))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train.values, y_train, epochs=5, batch_size=32, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.6474 - accuracy: 0.6086 - val_loss: 0.5970 - val_accuracy: 0.6651\n",
            "Epoch 2/5\n",
            "1488/1488 [==============================] - 37s 25ms/step - loss: 0.4481 - accuracy: 0.7876 - val_loss: 0.5363 - val_accuracy: 0.7459\n",
            "Epoch 3/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.6761 - val_accuracy: 0.7770\n",
            "Epoch 4/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.9484 - val_accuracy: 0.7846\n",
            "Epoch 5/5\n",
            "1488/1488 [==============================] - 38s 25ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.1446 - val_accuracy: 0.7894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2932167668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTe7y-afyXK8",
        "colab_type": "text"
      },
      "source": [
        "Hard: 0.688633839319\n",
        "\n",
        "Medium: \t0.627444380869\n",
        "\n",
        "Easy: \t0.578405304433"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Rstpr7zaOk",
        "colab_type": "text"
      },
      "source": [
        "Generate test data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvCbOB7zdhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate test data here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7sRey_4xjgB",
        "colab_type": "text"
      },
      "source": [
        "Predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVgIaenlxkYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}